{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/alexanderdesouza/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max.columns', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_headlines = pd.read_csv('./data/abcnews_million_headlines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_headlines.columns = ['date', 'headline']  # rename columns 'cause the others were verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['crown posts profit rise', 'interview des hasler',\n",
       "       'remembering albert henry jackson and the 1929 floods',\n",
       "       'conflicting claims over long bay escapee',\n",
       "       'interview daniel de silva',\n",
       "       'sunshine coast film hopes to be cut above the rest',\n",
       "       'listen to remote communities on climate change say women',\n",
       "       '10k needed to set up millicent penola menswatch',\n",
       "       'cup runneth over in madrid football parade',\n",
       "       'former malaysian pm sick in melbourne hospital',\n",
       "       'ukraine tension is more combustible than ever un told',\n",
       "       'rural qld john cox 2709', 'new dogs for biosecurity tasmania',\n",
       "       'warm weather puts crops in doubt',\n",
       "       'workers rally against ohs changes',\n",
       "       'new labelling laws proposed to reduce binge',\n",
       "       'dark nosed lions are fair game researchers say',\n",
       "       'socceroos happy to settle for germany draw',\n",
       "       'police probe road rage bashing',\n",
       "       'australian market abandon oil stocks as global'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_headlines.sample(20)['headline'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SIA()  # initialize a nltk semantic intensity analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_headlines = []\n",
    "\n",
    "for headline in raw_headlines.sample(20)['headline'].values:\n",
    "    sia_scores = sia.polarity_scores(headline)\n",
    "    sia_scores['headline'] = headline\n",
    "    scored_headlines.append(sia_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>headline</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>flying doctors future still up in the air</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>meredith hellicar quits last corporate post</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.5267</td>\n",
       "      <td>s korea slams n korean threat to civilian flights</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.7003</td>\n",
       "      <td>kimberley residents warned of tax phone scam</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.4215</td>\n",
       "      <td>lamb price struggling</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>country hour podcast 26 march</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0516</td>\n",
       "      <td>stosur reaches lucrative season ender</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0516</td>\n",
       "      <td>shooters miss double trap pairs medal</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.4019</td>\n",
       "      <td>15m to help open many rivers office</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>sa carryover</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.3818</td>\n",
       "      <td>horse flu sends beattie to warwick</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>pacific highway at ballina koala displacement ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>who is greece's new finance minister euclid ts...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>vic country hour 21 february 2014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.4767</td>\n",
       "      <td>heaston goes into history by accident</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>slow going for tasmanian nbn rollout</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.3637</td>\n",
       "      <td>cash threat wont stop code jumpers players rep</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>documents prove developers not misled over site</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.5719</td>\n",
       "      <td>tas parliament to celebrate anniversary in</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.3400</td>\n",
       "      <td>fire crews waiting for change in weather</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    compound                                           headline    neg    neu  \\\n",
       "0     0.0000          flying doctors future still up in the air  0.000  1.000   \n",
       "1     0.0000        meredith hellicar quits last corporate post  0.000  1.000   \n",
       "2    -0.5267  s korea slams n korean threat to civilian flights  0.362  0.638   \n",
       "3    -0.7003       kimberley residents warned of tax phone scam  0.537  0.463   \n",
       "4    -0.4215                              lamb price struggling  0.583  0.417   \n",
       "5     0.0000                      country hour podcast 26 march  0.000  1.000   \n",
       "6     0.0516              stosur reaches lucrative season ender  0.000  0.769   \n",
       "7     0.0516              shooters miss double trap pairs medal  0.390  0.300   \n",
       "8     0.4019                15m to help open many rivers office  0.000  0.690   \n",
       "9     0.0000                                       sa carryover  0.000  1.000   \n",
       "10   -0.3818                 horse flu sends beattie to warwick  0.342  0.658   \n",
       "11    0.0000  pacific highway at ballina koala displacement ...  0.000  1.000   \n",
       "12    0.0000  who is greece's new finance minister euclid ts...  0.000  1.000   \n",
       "13    0.0000                  vic country hour 21 february 2014  0.000  1.000   \n",
       "14   -0.4767              heaston goes into history by accident  0.383  0.617   \n",
       "15    0.0000               slow going for tasmanian nbn rollout  0.000  1.000   \n",
       "16   -0.3637     cash threat wont stop code jumpers players rep  0.301  0.532   \n",
       "17    0.0000    documents prove developers not misled over site  0.000  1.000   \n",
       "18    0.5719         tas parliament to celebrate anniversary in  0.000  0.575   \n",
       "19   -0.3400           fire crews waiting for change in weather  0.286  0.714   \n",
       "\n",
       "      pos  \n",
       "0   0.000  \n",
       "1   0.000  \n",
       "2   0.000  \n",
       "3   0.000  \n",
       "4   0.000  \n",
       "5   0.000  \n",
       "6   0.231  \n",
       "7   0.310  \n",
       "8   0.310  \n",
       "9   0.000  \n",
       "10  0.000  \n",
       "11  0.000  \n",
       "12  0.000  \n",
       "13  0.000  \n",
       "14  0.000  \n",
       "15  0.000  \n",
       "16  0.167  \n",
       "17  0.000  \n",
       "18  0.425  \n",
       "19  0.000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scored_headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct some regular expressions to be able to clean any text that is input into the system, and define a preprocessor method that lower cases the input text, \"cleans\" abbreviations, and removes general special characters, and strips dashes and underscores.\n",
    "\n",
    "This is one step up from rudimentary; the trouble with regex is you're never done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_abbr = re.compile(r'(?:^|\\s)((?:\\w(\\.\\s|\\s|\\.))(?:\\w\\2)+)', re.UNICODE)\n",
    "re_abbr_separator = re.compile(r'(\\s|\\.)', re.UNICODE)\n",
    "re_specialchar_removal = re.compile(r'(!|@|#|&|\\(|\\)|\\+|=|\\{|\\}|\\[|\\]|:|;|\\\"|\\'|,|\\?)', re.UNICODE)\n",
    "re_dash_removal = re.compile(r'-|_', re.UNICODE)\n",
    "\n",
    "\n",
    "def abbreviations_to_words(text):\n",
    "    \"\"\"\n",
    "    Converts all abbreviations found in the input string to a single word format.\n",
    "    \"\"\"\n",
    "    text += \" \"\n",
    "    all_abbreviations = [x[0] for x in re_abbr.findall(text + \" \")]\n",
    "    for abbreviation in all_abbreviations:\n",
    "        new_form = re_abbr_separator.sub('', abbreviation)\n",
    "        text = text.replace(abbreviation, new_form)\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocessor(text):\n",
    "    \"\"\"\n",
    "    Applies the following preprocessing steps to any input text:\n",
    "        - lowercases all text\n",
    "        - maps abbreviations to same format (e.g., A.D., A. D., A D to AD)\n",
    "        - removes general special characters (e.g., an '!' or an '&' symbol)\n",
    "        - splits words that contains dashes or underscores\n",
    "        - strips the any newline characters\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = abbreviations_to_words(text)\n",
    "    text = re_specialchar_removal.sub('', text)\n",
    "    text = re_dash_removal.sub(' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I Googled around for some headlines from CBC.ca/news, NPR.org, Bloomberg.com, and the MIT Technology Review (https://www.technologyreview.com/) to test the functionality of this preprocessing; the resulting examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_tests = [\"\\'Storm of a lifetime\\': 1.7 million ordered to flee approaching fury of Florence\",\n",
    "                  \"Trump Administration Transferred $9.8-Million From F.E.M.A. To I.C.E.\",\n",
    "                  \"A $100 Million Haircut for the Buyout Crowd\",\n",
    "                  \"Crypto Plunges 80%! Now Worse Than the Dot-Com Crash!\",\n",
    "                  \"How Bank Workers Emerged From the Crash $12.5 Billion Richer\",\n",
    "                  \"H.N.A.'s Debt Declines for First Time, Shrinking by $8.3-Billion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['storm of a lifetime 1.7 million ordered to flee approaching fury of florence',\n",
       " 'trump administration transferred $9.8 million from fema to ice',\n",
       " 'a $100 million haircut for the buyout crowd',\n",
       " 'crypto plunges 80% now worse than the dot com crash',\n",
       " 'how bank workers emerged from the crash $12.5 billion richer',\n",
       " 'hnas debt declines for first time shrinking by $8.3 billion']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl_processed_tests = []\n",
    "for hl in hl_tests:\n",
    "    hl_processed_tests.append(preprocessor(hl))\n",
    "\n",
    "hl_processed_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good enough! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do:\n",
    "#    - TF-IDF the input hl against the corpus of existing hls\n",
    "#    - return the top-n matches\n",
    "#    - from the top-n matches, select the top +vely and -vely sia scored matches to be returned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
