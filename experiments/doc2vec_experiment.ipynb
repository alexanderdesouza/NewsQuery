{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libs\n",
    "import random\n",
    "\n",
    "# DS libs\n",
    "import pandas as pd\n",
    "\n",
    "# Additional libraries\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA  # for compactness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/alexanderdesouza/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General notebook configs:\n",
    "pd.set_option('max.columns', 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used for this experiment comes from news headlines posted by the Austrailian Broadcasting Corporation (ABC News). The dataset consists of 1M such headlines and have already been substantially preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_headlines = pd.read_csv('../data/abcnews_million_headlines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>811562</th>\n",
       "      <td>20130815</td>\n",
       "      <td>mother of dead twins granted release on parole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777508</th>\n",
       "      <td>20130410</td>\n",
       "      <td>abbott accuses government of 'surrender' on bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991831</th>\n",
       "      <td>20151102</td>\n",
       "      <td>15 years of continuous human space time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                           headline\n",
       "811562  20130815     mother of dead twins granted release on parole\n",
       "777508  20130410  abbott accuses government of 'surrender' on bo...\n",
       "991831  20151102            15 years of continuous human space time"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_headlines.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_headlines.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ToDo** _Introduce sorting by date here to ensure the dataframe is ordered._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some headlines appear in duplicate; or do they..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, headline]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_headlines[raw_headlines.duplicated()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288438</th>\n",
       "      <td>20070227</td>\n",
       "      <td>closer am1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381259</th>\n",
       "      <td>20080504</td>\n",
       "      <td>nrl interview jason taylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714519</th>\n",
       "      <td>20120808</td>\n",
       "      <td>belinda varischetti interviews tim macnamara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653474</th>\n",
       "      <td>20111117</td>\n",
       "      <td>interview george bailey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446550</th>\n",
       "      <td>20090228</td>\n",
       "      <td>man charged over fatal stabbing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641190</th>\n",
       "      <td>20110925</td>\n",
       "      <td>abc entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780577</th>\n",
       "      <td>20130420</td>\n",
       "      <td>interview anthony faingaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801009</th>\n",
       "      <td>20130706</td>\n",
       "      <td>interview john cartwright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829825</th>\n",
       "      <td>20131026</td>\n",
       "      <td>interview alastair cook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929308</th>\n",
       "      <td>20150127</td>\n",
       "      <td>national rural news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                      headline\n",
       "288438  20070227                                    closer am1\n",
       "381259  20080504                    nrl interview jason taylor\n",
       "714519  20120808  belinda varischetti interviews tim macnamara\n",
       "653474  20111117                       interview george bailey\n",
       "446550  20090228               man charged over fatal stabbing\n",
       "641190  20110925                             abc entertainment\n",
       "780577  20130420                     interview anthony faingaa\n",
       "801009  20130706                     interview john cartwright\n",
       "829825  20131026                       interview alastair cook\n",
       "929308  20150127                           national rural news"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_headlines[raw_headlines.duplicated(subset=['headline'])==True].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random sampling of duplicate headlines indicates that duplicate headlines are the result of common news items - the weather, for example - that are recurrent, and for which the date provides a relevant distinguishing context. For this present analysis however, attribution of the date is encapsulated in the unique enumeration assigned to each article, so the `date` column can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = raw_headlines.drop('date', axis=1).copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next some simple processing is applied to reduce the input text to a simplified form against which matching can be reduced computationally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an eye toward a production-like environment, the following is constructed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stopwords=''):\n",
    "    \"\"\"\n",
    "    Given an input 'text' stop words are removed, reducing the complexity of the input text. A collection of stopwords must\n",
    "    be supplied, otherwise this method returns the input text directly again.\n",
    "        :param: text: Input string.\n",
    "        :return: Reduced complexity string.\n",
    "    \"\"\"\n",
    "    return ' '.join([word for word in text.split() if word not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines['stopped_headline'] = headlines['headline'].apply(lambda r: ' '.join([word for word in r.split() if word not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>stopped_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122741</th>\n",
       "      <td>meeting focuses on uni regional campus shake up</td>\n",
       "      <td>meeting focuses uni regional campus shake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14783</th>\n",
       "      <td>herron sigma merger complete</td>\n",
       "      <td>herron sigma merger complete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042307</th>\n",
       "      <td>mont blanc: rescue efforts suspended for stranded</td>\n",
       "      <td>mont blanc: rescue efforts suspended stranded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  headline  \\\n",
       "122741     meeting focuses on uni regional campus shake up   \n",
       "14783                         herron sigma merger complete   \n",
       "1042307  mont blanc: rescue efforts suspended for stranded   \n",
       "\n",
       "                                      stopped_headline  \n",
       "122741       meeting focuses uni regional campus shake  \n",
       "14783                     herron sigma merger complete  \n",
       "1042307  mont blanc: rescue efforts suspended stranded  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employ the semantic intensity analyzer from NLTK, `SIA`, a robust, but rule-based, lexicographic heuristic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ToDo** _Ideally semantic tagging can be learned from the text itself rather than being applied rotely._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SIA scored headlines here and skip the next 3 cells (the scoring below takes approximately 4 mins)\n",
    "scored_headlines = pd.read_pickle('../data/abcnews_million_headlines_sia_scored.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SIA()  # initialize the nltk semantic intensity analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SIA scoring of headlines: 1048575it [03:27, 5056.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# And score each of the headlines in the dataset\n",
    "scored_headlines = []\n",
    "\n",
    "for index, row in tqdm(headlines.iterrows(), desc='SIA scoring of headlines'):\n",
    "    sia_scores = sia.polarity_scores(row['stopped_headline'])\n",
    "    sia_scores['headline'] = row['headline']\n",
    "    sia_scores['stopped_headline'] = row['stopped_headline']\n",
    "    scored_headlines.append(sia_scores)\n",
    "    \n",
    "scored_headlines = pd.DataFrame(scored_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort columns as desired, for readability\n",
    "scored_headlines = scored_headlines[['headline', 'stopped_headline', 'neg', 'neu', 'pos', 'compound']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>stopped_headline</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541257</th>\n",
       "      <td>residents urge council to save sugarworld</td>\n",
       "      <td>residents urge council save sugarworld</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.4939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531064</th>\n",
       "      <td>grant money allocation decided soon</td>\n",
       "      <td>grant money allocation decided soon</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494119</th>\n",
       "      <td>smurray38 said it</td>\n",
       "      <td>smurray38 said</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         headline  \\\n",
       "541257  residents urge council to save sugarworld   \n",
       "531064        grant money allocation decided soon   \n",
       "494119                          smurray38 said it   \n",
       "\n",
       "                              stopped_headline  neg    neu    pos  compound  \n",
       "541257  residents urge council save sugarworld  0.0  0.556  0.444    0.4939  \n",
       "531064     grant money allocation decided soon  0.0  0.615  0.385    0.3612  \n",
       "494119                          smurray38 said  0.0  1.000  0.000    0.0000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_headlines.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the SIA scored headlines as it's quite a costly operation to generate them\n",
    "scored_headlines.to_pickle('../data/abcnews_million_headlines_sia_scored-22okt2018.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment can be corsely binned to create set(s) of document tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_sentiment_tag(score):\n",
    "    \"\"\"\n",
    "    A simple method returning 0 or 1 if the input score is considered either negative or positive.\n",
    "        :param: score: A value between [-1.0, +1.0]\n",
    "        :return: Integer value of 0 or 1\n",
    "    \"\"\"\n",
    "    return 0 if score < 0.0 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tagging Strategy** <br/>\n",
    "Two tags are introduced:\n",
    "1. The first is a single unique integer that could represent, for example, the unique date and time at which the article was published (though timestamps are unavailable).\n",
    "2. The second tag represents the output of the binary sentiment tag defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentence tagging: 1048575it [03:29, 5014.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['interview', 'ben', 'barba'], tags=[789946, 1]),\n",
       " TaggedDocument(words=['belinda', 'varischetti', 'interviews', 'rory', 'graham'], tags=[743795, 1]),\n",
       " TaggedDocument(words=['griffith', 'club', 'discuss', 'new', 'airspace', 'system'], tags=[55716, 1]),\n",
       " TaggedDocument(words=['growing', 'concern', 'potential', \"'needle\", 'stick', \"'\", 'inju'], tags=[819436, 1]),\n",
       " TaggedDocument(words=['man', 'dies', 'gyrocopter', 'crash'], tags=[535447, 0])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_docs = [TaggedDocument(words=nltk.word_tokenize(row['stopped_headline']), tags=[index, binary_sentiment_tag(row['compound'])]) for index, row in tqdm(scored_headlines.iterrows(), desc='Sentence tagging')]\n",
    "random.sample(tagged_docs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a set of hyperparameters that can be optimized later\n",
    "max_epochs = 100  # number of training epochs\n",
    "alpha = 0.025     # initial learning rate, selected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc2Vec(min_count=1, window=10, size=100, sample=1e-4, negative=5, workers=8)\n",
    "\n",
    "model = Doc2Vec(size=10,            # let's call it something like the number of neurons\n",
    "                alpha=alpha,        # learning rate\n",
    "                min_alpha=0.00025,  # minimum learning rate\n",
    "                min_count=1,        # minimum term frequency\n",
    "                dm =0.5)            # there is a trade off here in the degree of memory distribution to use for the model (i.e., DM v DBOW)\n",
    "\n",
    "model.build_vocab(tagged_docs)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_docs,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # Decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # Fix the learning rate to prevent decay\n",
    "    model.min_alpha = model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to file for reuse later\n",
    "model.save('./doc2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from file to reuse\n",
    "model = Doc2Vec.load('./doc2vec.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example(s) below is not relevant and will need to be modified slightly if loading and running this notebook from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A headline is randomly sampled from which a related query can be manually composed in order to assess the quality of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_headlines.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_query_statement = \"al qaeda bombing suspect\".split() # not stop words are pre-filtered in this composition\n",
    "query_vector = model.infer_vector(tokenized_query_statement)\n",
    "similarity = model.docvecs.most_similar([query_vector])\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = scored_headlines.iloc[list(dict(similarity).keys())]\n",
    "results['similarity'] = list(dict(similarity).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_headline_indexes = [int(i) for i, s in similarity]\n",
    "raw_headlines[matched_headline_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax([-0.1, -0.2, -0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
